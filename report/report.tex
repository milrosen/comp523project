% !TEX root = report/report.tex
% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[]{ACL2023}
\usepackage{amsmath}
\usepackage{amssymb}
% Standard package includes
\usepackage{times}
\usepackage{latexsym}
\usepackage{cancel}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Comp 523 Final Report}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{Milton Rosenbaum \\
  \textbf{milton.rosenbaum@mail.mcgill.ca} \\\And
  Asha Basu \\
  \textbf{asha.basu@mail.mcgill.ca}}

\begin{document}
\maketitle
\begin{abstract}
We implement a paper \cite{10.1007/978-3-540-30175-2_12} that lays out a type system for a simplified Scheme-like language with basic macros. Traditional type systems do not guarantee that macro expansion will not get stuck or produce untypable code; they merely catch errors after a macro has expanded, in a fashion uninformative to the user. This paper details our implementation of Culepper and Felleisen's \textit{shape types}, a new framework for reasoning about the types of macros, which ensures that macro evaluation does not get stuck (progress) and returns well-typed code (preservation), as proved in their paper.

\par Our code, along with some short examples and unit tests, can be found at \url{https://github.com/milrosen/comp523project}
\end{abstract}

\section{Introduction}

\subsection{Motivation \& History}
Macros are a very useful construct. If a programmer wishes to repeatedly perform some task on a certain syntactic pattern of code, rather than having to manually do so, they can simply code a macro to do it for them in some predetermined fashion. A macro might in general take in syntax of a certain \textit{pattern} -- that is, following some designated format (for example, a pair where the first element is itself a pair) and operate on it in some essentially arbitrary fashion; such macros can be defined and then used anywhere in code, and the interpreter will expand any macro it runs across, applying it to the subsequent code as its input format and replacing the two with the result of this application.\par

While macros in the sense of replacing text with other text in strings may date back further, Lisp-style macros that operate on abstract syntax trees date back to the 1960s, and have been used in many programming languages since then. However, such macros can often go awry. Using the paper's example, a programmer might define a macro meant to increment a number that, given some input, sets it to itself plus one; then, if the macro were applied to something other than a number, the program would return a type error when attempting to add one to something other than a number.\par

While errors due to misuse are of course a problem with any programming construct, the paper attempts to ameliorate this problem by combining shape checking and parsing. Normally, when such an error occurs, it would not be detected during macro expansion, as macros are not typed; then when detected during evaluation, the programmer will only receive a type error that addition was performed on a non-numerical input, rather than an error relating to what actually went wrong: the macro application. That is, in practice, we do not guarantee anything about the content of our variables, but the shape of the code that defines them.

The paper thus introduces a novel type system for macros themselves and macro expansion, which we implement. Actually typing the entirety of Scheme would be a herculean task, so the authors instead define a simplified, bare-bones version of Scheme with all the features truly essential to macros, and develop a type system for this programming language. We therefore implement this type system, testing both that it does what it intends to do and that it can be implemented at all, making sure that the inference rules are in fact syntax-directed.

\subsection{Overview}
This paper explains the simplified programming language in \cite{10.1007/978-3-540-30175-2_12} in the context of our implementation of it. We go over the paper's description of type checking, specifying our algorithmic interpretation of their rules. Before doing so, we go over some preliminaries, including the main aims of this type system. We assign \textit{shapes}, a specification of the syntactic \textit{form} of an expression program rather than the potential values of each variable, to each part of our program, allowing us to check if macros and keywords alike receive the correct inputs before they are expanded. We then go over each of the paper's judgments one by one.\par

First, there is the program correctness judgment, which represents the verification that a given program with some macros and expressions will run without type errors. Then there is the 'respects' relation $\vdash_{\mathcal R}$, which states that the macro environment -- a list of shapes that the type-checker has determined the macros to be -- does not contradict the definitions of the macros. We next outline what it means for any one macro's patterns and guards (from which its shape arises) to be respected by the macro environment.  To this end, we then detail two judgments: the \textit{unguarded} judgment $\vdash_{\mathcal U}$ which details the shape of the unguarded pattern in a macro's definition, and then \textit{guarded} judgment $\vdash_{\mathcal G}$ which details the shape of the guards in a macro's definition.\par

We then go over some more obvious judgments. One important judgment is the \textit{ordering} judgment $\sqsubseteq$, which checks when one shape is a more general version of another, analogous to subtyping. This is actually when the analog of the application rule for shape typing occurs: a macro applied to a shape is simply a subshape of the macro's output type. Another relatively simple judgment is the \textit{overlaps} judgment $\bowtie$, which determines whether two shapes share a possible input. Then there is the \textit{template} judgment $\vdash_{\mathcal T}$, which checks that a macro's output type matches its type annotation when its guard conditions are met. Then finally, there are the central judgments of the code: shape-checking ($\blacktriangleright$) and type-checking ($\circ$), which respectively generate the shape of a macro and type-check an expression against a type.\par

While this is all outlined in the paper, we explain how each judgment was implemented and how they relate to each other. That way, each judgment clearly is relevant to type-checking a macro rather than a series of unmotivated inference rules. We can then conclude the paper by summarizing the overall process. We also detail various challenges with implementing the paper and some possible extensions.

\section{Developments}


\subsection{Preliminaries}

The process of shape/type checking fulfills the same role as parsing in other languages. As such, it operates on an entirely unannotated abstract syntax tree. In our implementation, the AST is a list containing either symbols or smaller trees (ie lists). Instead of making judgments based on the runtime contents of our variables, we are interested in proving properties about the shape of the expressions themselves. As such, we only have two primitive types, $\textbf{expr}$ and $\textbf{def}$. These correspond to the valid shapes of forms in our toplevel.

In addition to the two primitive types, this paper also introduces complex shapes. These could be lists of other shapes, primitive types, identifiers, or arrows. The arrow shape is similar to a function type, and in the case of a macro, it does represent a transformation from one shape to another. However, arrow shapes are also powerful enough to represent the primitive keywords in our language. As such, we could give the keyword $\textbf{lambda}$ the shape $\textbf{(ident) expr} \rightarrow \textbf{expr}$, since the use of the keyword is valid if and only if it is followed by an identifier in parentheses and then a valid expression.

In this language, a macro definition is just a specification of the kinds of shapes that they expect to receive. These shapes are specified in clauses. For instance, the $\textbf{let}$ macro would have a single clause, with the pattern $\textbf{let (x y) z}$. In addition to a pattern, each clause needs a guard, specifying the shapes of each variable in the pattern. In the case of \textbf{let}, the guard would specify that the shape of the pattern is $\textbf{(ident expr) expr}$. 

Finally, a macro contains a template that determines the expansion that would take place after the clause is applied. Since our language has $\textbf{lambda}$ as a primitive keyword, the template of the $\textbf{let}$ macro would look like $(\textbf{lambda }(\textbf{x})\textbf{ z})\ \textbf{y}$.


\subsection{Implementations of Each Judgment}

\paragraph{Correctness} The primary judgment in the paper is correctness. Unlike a standard typing judgment, where each rule can be used at any point in a derivation tree, correctness is only ever used once, and its premises are just a list of the other judgments the code must satisfy. 

\[\begin{array}{c}
\multicolumn{1}{l}{md_i :=}\\
\multicolumn{1}{l}{(\textbf{define-syntax } m_i} \\\quad(\textbf{syntax-laws }t_i\ (P_{i,1}G_{i,1}T_{i,1}) \cdots)) \\[0.25cm]
\rho(m_i)=([(P_{i,j},G_{i,j},T_{i,j}), \cdots], t_i)\\
\Gamma \vdash_{\mathcal R} \rho \\
\Gamma \cup \Gamma_0;\Phi \vdash x_k \blacktriangleright t_k\quad t_k 
\in type \\\hline
\vdash_\mathcal P md_1 \cdots md_n \ x_1 \cdots x_{m} \textbf{ correct}\\
\end{array}\\[0.5cm]\]

As such, it is the entry point into our code. It is called on an abstract syntax tree. It specifies that a correct program begins with some number of macro definitions. Each must be composed of a name $m_i$, an output type $t_i$, and then a list of clauses, each comprised of a pattern $P_{i,j}$, guard $G_{i,j}$ and template $T_{i,j}$. Once we have ensured that the code actually follows this format, we assign the list of patterns, guards, and templates to the name of the macro in the expansion environment $\rho(m_i) = \dots$. Once we have associated the macro with the information needed to perform the eventual expansion, we ensure that it respects ($\vdash _\mathcal{R}$) the given environment. 

Once the shapes of our macros are generated, they are added to the macro context $\Gamma$. The context extended with $\Gamma_0$, containing the shapes of keywords, and $\Phi$, containing the shapes of pattern variables. Finally, these extended contexts are used to check that every toplevel form has a definite type. If macro-shape generation, template checking, and toplevel checking is successful, then the entire program is judged correct.  

\paragraph{Respects}
The respects judgment codifies when a macro definition is well-formed, and is also responsible for adding well-defined macros to the context for later checks. 
\[\begin{array}{c}
\forall m \in \textbf{dom}(\Gamma) \cap macro : \Gamma(m) \vdash_\mathcal R\rho (m) \\
\forall m \in \textbf{dom} (\rho) : \Gamma \vdash_\mathcal T \rho(m)
\\\hline
\Gamma \vdash_\mathcal R \rho
\end{array}\]
The first premise is responsible for generating the context $\Gamma$, which maps macros to their shape types. The second premise checks this context against the template code that our macros generate. This also mirrors the two key ways that a macro definition can be malformed: the patterns overlap, or it generates poorly shaped code. 
\paragraph{Macro Type}

Before we can check whether a macro is used correctly, we must define what it means to use that macro correctly. The macro type rule is responsible for turning the pattern and guard clauses into the shape of the macros.

\[\begin{array}{c}
\rho(m) = ([(P_0, G_0, T_0) \cdots (P_n,G_nT,_n)],t) \\
\Gamma(m) = (\textbf{mclauses} (u_1\ s_1) \cdots (u_n\ s_n)) \rightarrow t \\
\forall i \le n : G_i \vdash_\mathcal G P_i : s_i \\
\forall i \le n :\  \vdash_\mathcal U  P_i : u_i \\
\forall i \ne j : u_i \not\bowtie u_j
\\\hline
\Gamma(m) \vdash_\mathcal R \rho(m)
\end{array}\\[0.5cm]\]

Each macro and keyword are always an arrow shape since they expect code of a certain shape and return code of a different shape. The input shape for each macro will always be $\textbf{mclauses}$. This shape only ever appears as an input to a macro.  It will throw an error if it appears anywhere other than the first element of a form. 

Each $u_i, s_i$ pair in the shape corresponds to one of the guard clauses and specifies the shape that the clause is expecting to match. As such, the $\textbf{mclauses}$ shape acts like a logical or, and is a supershape of any shape which is a subshape of one of its clauses. The guarded ($\vdash_\mathcal G)$ and unguarded ($\vdash_\mathcal U)$ rules are responsible for generating the shapes of each clause. Note that they are both being called on the same pattern, but that only the guarded rule has access to the type specifications in the guards. 

After generating both guarded and unguarded shapes for each pattern, the final check ensures that there are no overlaps between any of the unguarded clauses. Since we don't have access to typing information during expansion, we need to be sure that the correct clause can be determined even from an untyped expression.

\paragraph{Guarded}

These are responsible for generating the shape of each macro. Note how the $G_i$ was on the left of the turnstile in the previous rule, where the $\Phi$ is now. Recall that $\Phi$ is the context that maps variables to types. The two judgments outline the recursive and base case of a function. In a given pattern we either have a list of forms, $x_1\dots x_n$, or a single pattern variable $p$. In the case of a list, we just recurse on each element of the list and look up single symbols in the $pvar$ context, $\Phi$. This judgment is also responsible for throwing an error if unbound variables appear in the pattern.

\[\begin{array}{c}
\text{Guarded1}\\
p \in pvar \qquad \Phi(p) = s \\\hline
\Phi \vdash_\mathcal G p : s
\\[0.35cm]
\text{Guarded2}\\
\forall i \le n : \Gamma;\Phi \vdash_\mathcal G x_i : s_i \\\hline
\Phi \vdash_\mathcal G (x_1 \cdots x_n) : (s_1 \cdots s_n)
\end{array} \\[0.5cm]\]

\paragraph{Unguarded}

These judgments are identical to the guard clauses, but instead of receiving a context, they map each symbol to the $\textbf{any}$ shape. 

\[\begin{array}{c}
\text{Unguarded1}\\
p \in pvar \\\hline
 \vdash_\mathcal U pvar : \textbf{any}\\[0.25cm]
\text{Unguarded2}\\
\forall i \le n : \ \ \ \vdash_\mathcal U x_i : u_i \\\hline
\vdash_\mathcal U (x_1 \cdots x_n) : (u_1 \cdots u_n)
\end{array}\]

\paragraph{Ordering}

For our shape type system to be useful, we need to have an ordering on shapes. For instance, if a macro expects an $\textbf{expr}$ in its first argument, it would be strange if we rejected $(\textbf{x y})$ for being an $(\textbf{ident ident})$, since every application of an identifier to another identifier is also an expression. 

This judgment is quite complex and is presented in natural deduction form in the paper. In the interest of time and space, I believe it is easier to write pseudocode directly. 
\[\arraycolsep=1.4pt
\begin{array}{rcll}
\_ &\sqsubseteq& \textbf{any}& \rightarrow true\\
    Type\ t_1 &\sqsubseteq& Type\ t_2 &\rightarrow t_1 = t_2 \\
    \textbf{ident} &\sqsubseteq& \textbf{expr} &\rightarrow true \\
    (s_1 \rightarrow t_1)\ s_2 &\sqsubseteq& Type\ t_2 &\rightarrow t_1 = t_2 \mathrel\& s_2 \sqsubseteq s_1 \\
    (s_1 \cdots s_n) &\sqsubseteq& (s'_1 \cdots s'_n) &\rightarrow \forall i \leq n,  s_i \sqsubseteq s_i'\\
    (s_1 \cdots s_n) &\sqsubseteq& \textbf{expr} &\rightarrow n \geq 2 \mathrel \& s_i \sqsubseteq \textbf{expr}\\
    s &\sqsubseteq& \multicolumn{2}{l}{\textbf{mclauses}\ (s_1,u_1) \cdots (s_n,u_n) }\\
     & & & \rightarrow \exists i \leq n, s \sqsubseteq s_i \\
    s_1 &\sqsubseteq& s_2 &\rightarrow s_1 = s_2
\end{array}\]
As a series of inference rules, the authors of the paper were able to simply add transitivity. However, this would no longer be syntax-directed, since we would effectively need to generate the middle shape from nowhere. However, it is not hard to verify that these rules are transitive.

It's also worth noting that this subshape judgment is by far the most important one in the paper. The arrow type rule, for instance, is where we ensure that the application of a macro or keyword is correct, as this doesn't actually happen in the typing judgment itself. Furthermore, the interaction of the arrow shape rule and the \textbf{mclauses} case is why the \textbf{mclauses} shape can represent the multiple possible clauses of a macro. 

\paragraph{Overlaps}
In the paper, the overlap rule, $u \bowtie u'$ is presented with its own inference rules. These rules are redundant, since they are identical to $u \sqsubseteq u' \vee u' \sqsubseteq u$, and we already have the unguarded rule which generates the type of a pattern by assigning $\textbf{any}$ to each symbol. 

Ensuring that no two patterns overlap in a macro imposes a substantial restriction on well-typed macros since $\textbf{any}$ always overlaps a list of any length. So, a macro with clauses for $(\textbf{ident ident})$ and $\textbf{ident}$ would be forbidden, since $(\textbf{any any}) \sqsubseteq \textbf{any}$. As such, it is impossible to create a series of similar clauses arranged from most specific to least specific, a very common design pattern for match-based control flow. However, the proof of progress and preservation requires that matching a clause is uniquely determined by the shape of untyped code.

\paragraph{Templates} After building our macro context, we check if the templates themselves are well-shaped. Interestingly, splitting the type checking into generating typing information for each macro and then typing the bodies of each macro means that we gain recursive macros for free, since we add each macro to $\Gamma$ as soon as we know its clauses are well typed. 

\paragraph{Shapes and Types} In the paper, the shape and type checker are split into two different judgments, $\Gamma;\Phi \vdash x \blacktriangleright t$, which checks if $x$ has type $t$, and $\Gamma;\Phi \vdash x \circ s$, which generates the shape of $x$. 

Since we generate the shape of an expression after we have finished creating our context, the function itself is very simple. It simply recurses until it reaches a lone symbol. If that symbol is a string or integer literal it returns the $\textbf{expr}$ shape. If the symbol is defined in the context (either $\Gamma$ or $\Phi)$, it returns the shape of that symbol. Finally, if the symbol is neither defined nor a literal, we return $\textbf{ident}$. As such, the expression $\textbf{lambda}\ (\textbf{x}) (\textbf{+ x 1})$ will be assigned the shape $((\textbf{ident})\ \textbf{expr} \rightarrow \textbf{expr})\ (\textbf{ident})\ (\textbf{ident ident expr})$. 

Unlike the typing judgments presented in class, this judgment never modifies the context, every $\Gamma;\Phi$ pair is the same in the premises and conclusion, it also does not contain a rule for macro application, which is handled in the shape ordering. 

After generating a shape for each piece of code, we ensure that each toplevel form in our program has a primitive type and not just a shape. In the paper, this typing judgment is not recursive, in each case, it simply asks for the shape generated by the shaping rule, and then checks if that shape is a subshape of $\textbf{expr}$ or $\textbf{def}$. This will be the case unless the code contains an incorrectly applied macro or there is a macro that generates a definition or expression when we were expecting the opposite. 

In the lambda example from earlier, we are interested in checking if $\Gamma; \Phi \vdash \textbf{lambda}\ (\textbf{x})\ (\textbf{+ x 1}) \blacktriangleright \textbf{expr}$. First, we check that the first symbol in our expression is a macro or keyword. Since it is, we look up the symbol in our context, and see that $\Gamma(\textbf{lambda}) = (\textbf{ident})\ \textbf{expr} \rightarrow \textbf{expr}$. Next, we check that the return type of our arrow shape is what our $\blacktriangleright$ expects. Then we check that the input shapes match, in this case, that $(\textbf{ident})\ (\textbf{ident ident expr}) \sqsubseteq (\textbf{ident})\ \textbf{expr}$. Since the two shapes are a list of the same length, and neither are a macro application, we check if the lists are pairwise subshapes of each other. In order, we see that $(\textbf{ident}) \sqsubseteq (\textbf{ident})$, and $(\textbf{ident ident expr}) \sqsubseteq \textbf{expr}$. The last check is true since the list on the left is longer than two and each element is individually a subshape of $\textbf{expr}$. 

\subsection{Implementation of Expansion}

Once we have a piece of code that type checks, we know that every macro produces code of a valid shape, and that every piece macro is only applied to code that it can work with. As such, if we were to expand our macros, we would never reach a stuck state.

Our overlaps relation ensured that each clause had a unique match without requiring any shape information. We simply reconstruct the unguarded shape of whatever code the macro is being applied to, and find the first guard clause which is a supershape of the unguarded interpretation. From there, we match up the pattern and symbolic expression to generate a substitution, perform that substitution on the template, and then expand the post-substitution template, since our macros may be recursive. 

\subsection{Challenges}

There were two major challenges in implementing this paper. First, the judgments, as presented, give no real indication of their role in computation. Second, the only example of a macro written in the language of the paper uses a significantly more complex shape system. The paper does not explain how the previous judgments needed to be extended to use the advanced typing features that they require.

For each judgment, the process of reconstructing the correct computational interpretation was an exercise in unprincipled guesswork. For instance, we interpreted the shaping judgment as generating the least possible shape of a given piece of code. However, this is not found anywhere in the paper, in fact, the shaping judgment contains a conversion rule based on the subshape relation, which makes it look much more like a traditional derivation tree than it is in our interpretation. 

Further confusing this is the fact that the shape ordering is already transitive and contains the rule for applications. Indeed, we never check if a shape on the left of the circle is syntactically equal to another shape, only that it is a sub-shape of the type or macro argument that we are checking. As such, both rules are defined with transitivity independently.

Similar challenges to these popped up in almost every step of our implementation. We found it difficult to determine whether rules added variables to a context or checked membership in the context. Usually, this is disambiguated by writing $\Gamma, x :A \vdash M :C$ when $x$ is added, and $\Gamma(x) = A$ when $x$ is being checked, however, the first format never appears in the paper, and both additions and checks were seemingly written in the later format. 

In addition to a lack of clarity on the role of each rule, the order of operations was also very difficult to determine. For instance, it seems reasonable to assume that type and shape checking should occur before expansion, and, indeed, the result of the correctness judgment is a program that contains macro definitions, and so must not have been expanded. However, the authors of the paper define a keyword, $\textbf{app}$, which can only appear after expansion, and indicates that an s-expr has been tagged as a procedure application rather than a macro application. Inexplicably, this keyword, which should never appear during type checking, is added to the initial context in which the program is checked. 

Furthermore, the correctness judgment includes $\Gamma\cup\Gamma_0; \Phi \vdash x_k \blacktriangleright t_k\quad t_k \in type$ as a premise. The $\Phi$ represents a context mapping pattern variables to shapes. Since $pvars$ should never appear outside of the template of a macro, it is unclear how to interpret this. Nevertheless, $\Phi$  appears. In other situations where a context should be empty, the authors use a $\cdot$ or just a space, so, it seems to be the case that there should be a non-empty pattern variable context for our toplevel forms, how this context should be defined is left undetermined by the paper, further compounding our confusion on the role of each rule.

The second batch of challenges crop up when their paper is compared to their example, the \textbf{cond} macro. It turns an expression to be evaluated and a list of (premise, result) pairs and transforms it into a nested if expression which will return the first expression whose predicate is true. To define this macro in a type-safe way, the authors introduce three extensions to their shape type system. First, the ability to define keywords -- shape types that are inhabited by a single symbol -- like $\textbf{else}$ or $\textbf{=>}$. Second, union shapes, which should be supershapes of any element in their union. Finally, they introduce arbitrary-length lists which should match either $\textbf{nil}$ or $(\textbf{cons }s\ (\textbf{list} \ s))$. 

While it is easy to check when a union shape is a subshape of a non-union shape, it is much more difficult to check that a set of macro clauses exhaust the union shape, especially considering that union shapes may contain the list shape or other union shapes. However, since the authors apply macros directly to union shapes in their code, this is a must if we want to have preservation and progress.

This is much more complicated than any of the cases presented in the paper, and no guidance is presented on how it could be achieved. Further, operating on lists of arbitrary length is essential for defining key lisp macros, such as $\textbf{(let* [x (expr) ... z (expr)] in expr)}$, which binds any number of identifiers to the result of evaluating the expression on their right. It should only ever shape-check on applications to lists of $\textbf{ident (expr)}$ pairs. This means that there would need to be at least two clauses in the definition of let, one which matches $\textbf{nil}$ case of the list, and one which matches the $\textbf{cons}$ case. These two clauses would be defined separately since they match on different shapes. In the body of the $\textbf{cons}$ case, we would need to apply the macro on the shorter list. For this application to be correct, we would need some way of checking that the macro clauses cover both the \textbf{nil} and \textbf{cons} cases of the list shape. 

However, as defined, an application of a macro is valid iff exactly one of the cases matches the given input shape. Obviously, there is no one clause in the let macro that could match both the \textbf{nil} and \textbf{cons} case, since they have different shapes, meaning that the judgment would need to be extended somehow. This extension would be complicated, since it would need to determine when macro clauses exhaust an arbitrary shape, which may contain deeply nested unions and lists. The paper does not indicate what is involved in implementing these essential extensions.

% for challenges, and I assume that this will be at least a page or two, I would wanna write that the inner workings of each judgment are more-or-less a mystery for me. To explain that, we would need an explanation of the core/surface grammar, and how the app case really doesn't fit in with the rest of the paper. "Before parsing" what a joke.

\section{Conclusion}
In the paper, Culpepper and Felleisen discuss many extensions that could be implemented, chiefly including sequences of arbitrary length, without providing any concrete way to do so. Thus the type system they detail is a long way from being able to fully match Scheme macros, even though they claim that, in practice, most Scheme code can be written under the simplifying constraints that this type-checker assumes. Thus the most obvious avenue of future work would be to figure out how to implement these extensions. Additionally, their paper omits hygiene and referential transparency; implementing those would also be a useful extension that would make this type-system closer to be useful for Scheme as it is actually used.\par

Furthermore, this is not the only line of research into type systems for macros. While this specific type system has not been built on very much in the literature, there are many diverse ways of attempting to type-check macros, some by the author of this paper himself. Ideally, future research into this topic would also attempt to implement some other such proposals, perhaps with an attempt to capture more functionality than is in this paper's simplified programming language.\par

To recap, this paper implements an already-existing type system for macros outlined in \cite{10.1007/978-3-540-30175-2_12}. To do so, it first goes through what it is the paper is trying to do, outlining the broad idea. It then explains the paper's various judgments in its type system, and explains what they mean and how they are implemented in the corresponding code. Afterward, it ties them together under one unified explanation for what this type-checking algorithm is fundamentally doing, and concludes with an outline of some of the challenges faces and possible extensions.

\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}



\appendix

\end{document}